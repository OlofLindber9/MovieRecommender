{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 · TMDB Feature Enrichment\n",
    "\n",
    "Enrich every movie with signals from **The Movie Database (TMDB)**:\n",
    "\n",
    "| Feature | Description | How used |\n",
    "|---------|-------------|----------|\n",
    "| `overview` | Plot summary (1-2 paragraphs) | TF-IDF, merged into CB tag string |\n",
    "| `director` | Primary director name | Binary feature per director |\n",
    "| `top_cast` | Top 5 billed cast members | Binary features |\n",
    "| `keywords` | TMDB keyword tags | Merged into tag string |\n",
    "| `runtime`, `vote_average` | Runtime & global rating | Numeric features |\n",
    "\n",
    "The fetcher caches every response to `data/external/tmdb_cache.json`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7deeb9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found (6e8d…)\n",
      "Paths OK: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import requests\n",
    "\n",
    "# find_dotenv() walks up from the notebook directory until it finds .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "ROOT    = Path.cwd().parents[1]\n",
    "SRC     = ROOT / 'src'\n",
    "FEAT    = SRC / 'data' / 'features'\n",
    "PROC    = SRC / 'data' / 'processed'\n",
    "RAW     = SRC / 'data' / 'raw' / 'ml-25m'\n",
    "EXT     = SRC / 'data' / 'external'\n",
    "MODELS  = SRC / 'models'\n",
    "EXT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TMDB_KEY      = os.environ.get('TMDB_API_KEY', '')\n",
    "TMDB_BASE     = 'https://api.themoviedb.org/3'\n",
    "CACHE_FILE    = EXT / 'tmdb_cache.json'\n",
    "RATE_LIMIT    = 40   # requests per 10 seconds (TMDB free tier)\n",
    "\n",
    "if not TMDB_KEY:\n",
    "    print('⚠  TMDB_API_KEY not set — API calls will be skipped.')\n",
    "    print('   Set the env var and re-run, or use the cached data if available.')\n",
    "else:\n",
    "    print(f'API key found ({TMDB_KEY[:4]}…)')\n",
    "\n",
    "print('Paths OK:', FEAT.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 · Load MovieLens Links (TMDB IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with TMDB IDs: 32,388 / 32,424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>114709</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  imdbId  tmdbId\n",
       "0        1  114709     862\n",
       "1        2  113497    8844\n",
       "2        3  113228   15602"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df   = pd.read_parquet(PROC / 'links_cleaned.parquet')\n",
    "movies_df  = pd.read_parquet(FEAT / 'movie_features.parquet')\n",
    "\n",
    "# Only fetch for movies that are in the processed feature set\n",
    "valid_ids  = set(movies_df['movieId'])\n",
    "links_df   = links_df[links_df['movieId'].isin(valid_ids)].copy()\n",
    "links_df   = links_df.dropna(subset=['tmdbId'])\n",
    "links_df['tmdbId'] = links_df['tmdbId'].astype(int)\n",
    "\n",
    "print(f'Movies with TMDB IDs: {len(links_df):,} / {len(movies_df):,}')\n",
    "links_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 · TMDB API Fetcher (with Caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fresh cache.\n",
      "Fetcher ready.\n"
     ]
    }
   ],
   "source": [
    "# Load existing cache\n",
    "if CACHE_FILE.exists():\n",
    "    with open(CACHE_FILE) as f:\n",
    "        cache = json.load(f)\n",
    "    print(f'Loaded cache: {len(cache):,} entries')\n",
    "else:\n",
    "    cache = {}\n",
    "    print('Starting fresh cache.')\n",
    "\n",
    "\n",
    "def save_cache():\n",
    "    with open(CACHE_FILE, 'w') as f:\n",
    "        json.dump(cache, f)\n",
    "\n",
    "\n",
    "_request_times = []\n",
    "\n",
    "def tmdb_get(endpoint, params=None):\n",
    "    \"\"\"Rate-limited TMDB GET with caching. Returns parsed JSON or None.\"\"\"\n",
    "    key = endpoint + str(sorted((params or {}).items()))\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "\n",
    "    if not TMDB_KEY:\n",
    "        return None\n",
    "\n",
    "    # Enforce rate limit: ≤ RATE_LIMIT requests per 10 seconds\n",
    "    now = time.time()\n",
    "    _request_times[:] = [t for t in _request_times if now - t < 10]\n",
    "    if len(_request_times) >= RATE_LIMIT:\n",
    "        sleep_for = 10 - (now - _request_times[0]) + 0.1\n",
    "        time.sleep(max(sleep_for, 0))\n",
    "    _request_times.append(time.time())\n",
    "\n",
    "    url  = f'{TMDB_BASE}/{endpoint}'\n",
    "    resp = requests.get(url, params={'api_key': TMDB_KEY, **(params or {})})\n",
    "\n",
    "    if resp.status_code == 200:\n",
    "        data = resp.json()\n",
    "        cache[key] = data\n",
    "        return data\n",
    "    elif resp.status_code == 429:\n",
    "        time.sleep(10)\n",
    "        return tmdb_get(endpoint, params)\n",
    "    else:\n",
    "        cache[key] = None\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_movie_details(tmdb_id):\n",
    "    \"\"\"Fetch movie details + credits + keywords in one call.\"\"\"\n",
    "    return tmdb_get(\n",
    "        f'movie/{tmdb_id}',\n",
    "        params={'append_to_response': 'credits,keywords'}\n",
    "    )\n",
    "\n",
    "\n",
    "print('Fetcher ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 · Fetch Data for Top Movies\n",
    "\n",
    "Fetching all 32 k movies takes might take to long. fetches top 500 movies for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will fetch 5,000 movies\n",
      "  500/5,000 fetched, cache saved\n",
      "  1,000/5,000 fetched, cache saved\n",
      "  1,500/5,000 fetched, cache saved\n",
      "  2,000/5,000 fetched, cache saved\n",
      "  2,500/5,000 fetched, cache saved\n",
      "  3,000/5,000 fetched, cache saved\n",
      "  3,500/5,000 fetched, cache saved\n",
      "  4,000/5,000 fetched, cache saved\n",
      "  4,500/5,000 fetched, cache saved\n",
      "  5,000/5,000 fetched, cache saved\n",
      "Done — 5,000 movies fetched, cache saved to c:\\Users\\ololi\\StudioProjects\\movie-recommender\\src\\data\\external\\tmdb_cache.json\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 5000   # set to None to fetch all\n",
    "\n",
    "# Sort by popularity so most-impactful movies are fetched first\n",
    "fetch_queue = (\n",
    "    movies_df[['movieId', 'num_ratings']]\n",
    "    .merge(links_df[['movieId', 'tmdbId']], on='movieId')\n",
    "    .sort_values('num_ratings', ascending=False)\n",
    ")\n",
    "if TOP_N:\n",
    "    fetch_queue = fetch_queue.head(TOP_N)\n",
    "\n",
    "print(f'Will fetch {len(fetch_queue):,} movies')\n",
    "\n",
    "# Actually fetch (skip if API key missing)\n",
    "if TMDB_KEY:\n",
    "    SAVE_EVERY = 500\n",
    "    fetched = 0\n",
    "    for _, row in fetch_queue.iterrows():\n",
    "        tmdb_id = int(row['tmdbId'])\n",
    "        fetch_movie_details(tmdb_id)   # result stored in cache automatically\n",
    "        fetched += 1\n",
    "        if fetched % SAVE_EVERY == 0:\n",
    "            save_cache()\n",
    "            print(f'  {fetched:,}/{len(fetch_queue):,} fetched, cache saved')\n",
    "    save_cache()\n",
    "    print(f'Done — {fetched:,} movies fetched, cache saved to {CACHE_FILE}')\n",
    "else:\n",
    "    print('Skipping API fetch (no key).  Run with TMDB_API_KEY set to populate cache.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 · Parse Cache into a Feature DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 4,986 TMDB records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_avg</th>\n",
       "      <th>director</th>\n",
       "      <th>top_cast</th>\n",
       "      <th>keywords</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a low IQ has accomplished great thi...</td>\n",
       "      <td>142</td>\n",
       "      <td>8.462</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>[Tom Hanks, Robin Wright, Gary Sinise, Sally F...</td>\n",
       "      <td>[new year's eve, vietnam war, vietnam veteran,...</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imprisoned in the 1940s for the double murder ...</td>\n",
       "      <td>142</td>\n",
       "      <td>8.715</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>[Tim Robbins, Morgan Freeman, Bob Gunton, Will...</td>\n",
       "      <td>[prison, friendship, police brutality, corrupt...</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  runtime  vote_avg  \\\n",
       "0  A man with a low IQ has accomplished great thi...      142     8.462   \n",
       "1  Imprisoned in the 1940s for the double murder ...      142     8.715   \n",
       "\n",
       "          director                                           top_cast  \\\n",
       "0  Robert Zemeckis  [Tom Hanks, Robin Wright, Gary Sinise, Sally F...   \n",
       "1   Frank Darabont  [Tim Robbins, Morgan Freeman, Bob Gunton, Will...   \n",
       "\n",
       "                                            keywords  movieId  \n",
       "0  [new year's eve, vietnam war, vietnam veteran,...      356  \n",
       "1  [prison, friendship, police brutality, corrupt...      318  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(tmdb_id):\n",
    "    \"\"\"Extract structured features from a cached TMDB response.\"\"\"\n",
    "    key  = f'movie/{tmdb_id}' + str(sorted({'append_to_response': 'credits,keywords'}.items()))\n",
    "    data = cache.get(key)\n",
    "    if not data:\n",
    "        return None\n",
    "\n",
    "    # Overview / plot summary\n",
    "    overview = (data.get('overview') or '').strip()\n",
    "\n",
    "    # Runtime (minutes)\n",
    "    runtime = data.get('runtime')\n",
    "\n",
    "    # TMDB vote average (independent of MovieLens ratings)\n",
    "    vote_avg = data.get('vote_average')\n",
    "\n",
    "    # Director (take first director from crew)\n",
    "    credits  = data.get('credits', {})\n",
    "    crew     = credits.get('crew', [])\n",
    "    director = next(\n",
    "        (c['name'] for c in crew if c.get('job') == 'Director'), None\n",
    "    )\n",
    "\n",
    "    # Top-5 cast\n",
    "    cast_list = credits.get('cast', [])\n",
    "    top_cast  = [c['name'] for c in sorted(cast_list,\n",
    "                    key=lambda x: x.get('order', 999))[:5]]\n",
    "\n",
    "    # Keywords\n",
    "    kws = data.get('keywords', {}).get('keywords', [])\n",
    "    keywords = [k['name'] for k in kws]\n",
    "\n",
    "    return {\n",
    "        'overview': overview,\n",
    "        'runtime':  runtime,\n",
    "        'vote_avg': vote_avg,\n",
    "        'director': director,\n",
    "        'top_cast': top_cast,\n",
    "        'keywords': keywords,\n",
    "    }\n",
    "\n",
    "\n",
    "# Build TMDB feature DataFrame\n",
    "tmdb_rows = []\n",
    "for _, row in fetch_queue.iterrows():\n",
    "    feats = extract_features(int(row['tmdbId']))\n",
    "    if feats:\n",
    "        feats['movieId'] = int(row['movieId'])\n",
    "        tmdb_rows.append(feats)\n",
    "\n",
    "tmdb_df = pd.DataFrame(tmdb_rows)\n",
    "print(f'Parsed {len(tmdb_df):,} TMDB records')\n",
    "tmdb_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 · Merge with Movie Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with overview:  4,986\n",
      "Movies with director:  4,986\n",
      "Total movies:          32,424\n"
     ]
    }
   ],
   "source": [
    "# Merge TMDB features into the main movies DataFrame\n",
    "enriched_df = movies_df.merge(\n",
    "    tmdb_df[['movieId', 'overview', 'runtime', 'vote_avg', 'director',\n",
    "             'top_cast', 'keywords']],\n",
    "    on='movieId', how='left'\n",
    ")\n",
    "\n",
    "n_with_overview = enriched_df['overview'].notna().sum()\n",
    "n_with_director = enriched_df['director'].notna().sum()\n",
    "print(f'Movies with overview:  {n_with_overview:,}')\n",
    "print(f'Movies with director:  {n_with_director:,}')\n",
    "print(f'Total movies:          {len(enriched_df):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 · Build Enriched Tag String\n",
    "\n",
    "Concatenate the existing `tag_string` with:\n",
    "- Plot overview words\n",
    "- Director name\n",
    "- Cast names\n",
    "- TMDB keywords\n",
    "\n",
    "This single string is then fed into TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Toy Story (1995)\n",
      "Text snippet: john_lasseter john_lasseter john_lasseter tom_hanks tom_hanks tim_allen tim_allen don_rickles don_rickles jim_varney jim_varney wallace_shawn wallace_shawn rescue friendship mission jealousy villain bullying elementary_school rivalry anthropomorphism friends computer_animation buddy walkie_talkie to …\n"
     ]
    }
   ],
   "source": [
    "def build_enriched_text(row):\n",
    "    parts = []\n",
    "\n",
    "    # Existing user tags\n",
    "    if pd.notna(row.get('tag_string')) and row['tag_string']:\n",
    "        parts.append(str(row['tag_string']))\n",
    "\n",
    "    # Director (repeated 3x for higher weight)\n",
    "    if pd.notna(row.get('director')) and row['director']:\n",
    "        director_tok = row['director'].lower().replace(' ', '_')\n",
    "        parts.extend([director_tok] * 3)\n",
    "\n",
    "    # Cast (repeated 2x)\n",
    "    if isinstance(row.get('top_cast'), list):\n",
    "        for name in row['top_cast']:\n",
    "            cast_tok = name.lower().replace(' ', '_')\n",
    "            parts.extend([cast_tok] * 2)\n",
    "\n",
    "    # TMDB keywords\n",
    "    if isinstance(row.get('keywords'), list):\n",
    "        parts.extend([k.lower().replace(' ', '_') for k in row['keywords']])\n",
    "\n",
    "    # Overview (plain text — TF-IDF will tokenise)\n",
    "    if pd.notna(row.get('overview')) and row['overview']:\n",
    "        parts.append(row['overview'].lower())\n",
    "\n",
    "    return ' '.join(parts)\n",
    "\n",
    "\n",
    "enriched_df['enriched_text'] = enriched_df.apply(build_enriched_text, axis=1)\n",
    "\n",
    "# Preview\n",
    "sample = enriched_df[enriched_df['enriched_text'].str.len() > 50].iloc[0]\n",
    "print(f\"Movie: {sample['title']}\")\n",
    "print(f\"Text snippet: {sample['enriched_text'][:300]} …\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 · Re-train TF-IDF on Enriched Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 32,424 documents\n",
      "Non-empty: 4,986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Use positions aligned with movie_id_map\n",
    "with open(FEAT / 'id_mappings.pkl', 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "\n",
    "movie_id_map = mappings['movie_id_map']\n",
    "n_movies     = len(movie_id_map)\n",
    "\n",
    "enriched_indexed = enriched_df.set_index('movieId')\n",
    "\n",
    "# Build text corpus in movie_idx order\n",
    "corpus = []\n",
    "valid_movie_ids = []\n",
    "for movie_id in sorted(movie_id_map, key=lambda m: movie_id_map[m]):\n",
    "    if movie_id in enriched_indexed.index:\n",
    "        text = enriched_indexed.loc[movie_id, 'enriched_text']\n",
    "        corpus.append(text if isinstance(text, str) else '')\n",
    "        valid_movie_ids.append(movie_id)\n",
    "    else:\n",
    "        corpus.append('')\n",
    "        valid_movie_ids.append(movie_id)\n",
    "\n",
    "print(f'Corpus size: {len(corpus):,} documents')\n",
    "print(f'Non-empty: {sum(1 for t in corpus if t):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix: (32424, 3000)\n",
      "Top 20 features: ['the', 'to', 'and', 'of', 'in', 'his', 'is', 'with', 'an', 'he', 'for', 'on', 'her', 'their', 'when', 'that', 'by', 'as', 'who', 'from']\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features = 3000,      # more features than original (was 1000)\n",
    "    min_df       = 3,         # lower threshold catches rare directors / actors\n",
    "    ngram_range  = (1, 2),\n",
    "    sublinear_tf = True,\n",
    "    strip_accents = 'unicode',\n",
    ")\n",
    "\n",
    "tfidf_mat = tfidf.fit_transform(corpus)   # (n_movies, 3000)\n",
    "print(f'TF-IDF matrix: {tfidf_mat.shape}')\n",
    "\n",
    "# Top distinctive terms\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "mean_tfidf    = np.asarray(tfidf_mat.mean(axis=0)).ravel()\n",
    "top_idx       = mean_tfidf.argsort()[::-1][:20]\n",
    "print('Top 20 features:', list(feature_names[top_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 · Combine TF-IDF with Genre Features → New CB Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined feature matrix: (32424, 3020)\n"
     ]
    }
   ],
   "source": [
    "genre_cols   = [c for c in enriched_df.columns if c.startswith('genre_')]\n",
    "n_genres     = len(genre_cols)\n",
    "\n",
    "# Genre feature matrix in movie_idx order\n",
    "genre_data   = np.zeros((n_movies, n_genres), dtype=np.float32)\n",
    "for movie_id, midx in movie_id_map.items():\n",
    "    if movie_id in enriched_indexed.index:\n",
    "        genre_data[midx] = enriched_indexed.loc[movie_id, genre_cols].values.astype(np.float32)\n",
    "\n",
    "genre_mat = sp.csr_matrix(genre_data)\n",
    "\n",
    "# Weighted combination: TF-IDF (weight 2) + genres (weight 1)\n",
    "combined  = sp.hstack([tfidf_mat * 2.0, genre_mat * 1.0], format='csr')\n",
    "\n",
    "# L2-normalise each row so dot product = cosine similarity\n",
    "combined_norm = normalize(combined, norm='l2')\n",
    "\n",
    "print(f'Combined feature matrix: {combined_norm.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 · Quick Sanity Check — Movie Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to Toy Story (1995) — enriched CB:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>director</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frozen II (2019)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wild, The (2006)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aladdin (1992)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Penguin Highway (2018)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brother Bear 2 (2006)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tale of Despereaux, The (2008)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wonder Park (2019)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Toy Story Toons: Small Fry (2011)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toy Story Toons: Hawaiian Vacation (2011)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DuckTales: The Movie - Treasure of the Lost La...</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                   Frozen II (2019)   \n",
       "1                                   Wild, The (2006)   \n",
       "2                                     Aladdin (1992)   \n",
       "3                             Penguin Highway (2018)   \n",
       "4                              Brother Bear 2 (2006)   \n",
       "5                     Tale of Despereaux, The (2008)   \n",
       "6                                 Wonder Park (2019)   \n",
       "7                  Toy Story Toons: Small Fry (2011)   \n",
       "8          Toy Story Toons: Hawaiian Vacation (2011)   \n",
       "9  DuckTales: The Movie - Treasure of the Lost La...   \n",
       "\n",
       "                                        genres  director  similarity  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "1  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "2  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "4  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "5  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "6  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "7  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "8  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  \n",
       "9  Adventure|Animation|Children|Comedy|Fantasy       NaN      0.7454  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similar_movies(movie_id, n=10):\n",
    "    if movie_id not in movie_id_map:\n",
    "        print('Movie not found.')\n",
    "        return\n",
    "    midx = movie_id_map[movie_id]\n",
    "    sims = (combined_norm @ combined_norm[midx].T).toarray().ravel()\n",
    "    sims[midx] = -1\n",
    "    top  = np.argsort(sims)[::-1][:n]\n",
    "    rows = []\n",
    "    for t in top:\n",
    "        mid = mappings['idx_to_movie'].get(t)\n",
    "        if mid and mid in enriched_indexed.index:\n",
    "            r = enriched_indexed.loc[mid]\n",
    "            rows.append({'title': r['title'], 'genres': r['genres'],\n",
    "                         'director': r.get('director'), 'similarity': round(float(sims[t]), 4)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Toy Story (movieId=1)\n",
    "print('Similar to Toy Story (1995) — enriched CB:')\n",
    "similar_movies(1, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 · Save Enriched CB Model\n",
    "\n",
    "Save this as a drop-in replacement for `cb_model.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70670507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "  src/models/cb_enriched_model.pkl\n",
      "  src/data/features/movie_features_enriched.parquet\n",
      "\n",
      "Feature matrix: (32424, 3020)  (was 32424 x 1020 before TMDB)\n",
      "Lookup entries: 32,424\n"
     ]
    }
   ],
   "source": [
    "# Build index maps matching the ACTUAL key names in cb_model.pkl:\n",
    "#   movie_idx_lookup  – {movie_id → row in feature matrix}\n",
    "#   idx_to_movie_id   – {row → movie_id}\n",
    "# The corpus was built in movie_idx order, so row midx = movie at mappings['idx_to_movie'][midx]\n",
    "idx_to_movie = mappings['idx_to_movie']   # {movie_idx → movie_id}\n",
    "\n",
    "movie_idx_lookup = {idx_to_movie[midx]: midx for midx in range(n_movies)\n",
    "                    if midx in idx_to_movie}\n",
    "idx_to_movie_id  = {midx: idx_to_movie[midx] for midx in range(n_movies)\n",
    "                    if midx in idx_to_movie}\n",
    "\n",
    "cb_enriched = {\n",
    "    # Keys match the original cb_model.pkl so all downstream code works unchanged\n",
    "    'movie_feature_matrix': combined_norm,\n",
    "    'movie_idx_lookup':     movie_idx_lookup,   # {movie_id → row}\n",
    "    'idx_to_movie_id':      idx_to_movie_id,    # {row → movie_id}\n",
    "    'tfidf':                tfidf,\n",
    "    'genre_cols':           genre_cols,\n",
    "    'weights':              {'tfidf': 2.0, 'genres': 1.0},\n",
    "    'rating_midpoint':      3.0,\n",
    "    # Metadata\n",
    "    'enriched':             True,\n",
    "    'n_tfidf_features':     tfidf_mat.shape[1],\n",
    "    'n_genre_features':     n_genres,\n",
    "    'tmdb_movies_count':    len(tmdb_df),\n",
    "}\n",
    "\n",
    "with open(MODELS / 'cb_enriched_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cb_enriched, f)\n",
    "\n",
    "# Save enriched movie features for use in the app\n",
    "enriched_df.drop(columns=['top_cast', 'keywords'], errors='ignore') \\\n",
    "           .to_parquet(FEAT / 'movie_features_enriched.parquet', index=False)\n",
    "\n",
    "print('Saved:')\n",
    "print('  src/models/cb_enriched_model.pkl')\n",
    "print('  src/data/features/movie_features_enriched.parquet')\n",
    "print()\n",
    "print(f'Feature matrix: {combined_norm.shape}  (was {tfidf_mat.shape[0]} x 1020 before TMDB)')\n",
    "print(f'Lookup entries: {len(movie_idx_lookup):,}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie-rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
